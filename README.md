# A REPRODUCIBILITY STUDY OF TRANSTAB: LEARNING TRANSFERABLE TABULAR TRANSFORMERS ACROSS TABLES
Created by <a href="https://github.com/albertotamajo" target="_blank">Alberto Tamajo</a>, <a href="https://github.com/JakubDylag" target="_blank">Jakub Dylag</a>, <a href="" target="_blank">Alessandro Nerla</a> and <a href="" target="_blank">Laurin Lanz</a>.

### Introduction
The ubiquity of tabular data in machine learning led Wang & Sun (2022) to introduce a versatile tabular learning framework, Transferable Tabular Transformer (TransTab), capable of modelling variable-column tables. Furthermore, they proposed a novel technique that enables supervised or self-supervised pretraining on multiple tables, as well as finetuning on the target dataset. Given the potential impact of their work, we aim to verify their claims by trying to reproduce their re-
sults. Specifically, we try to corroborate the ’methods’ and ’results’ reproducibility of their paper.
Verifying the reproducibility of "TransTab: Learning Transferable Tabular Transformers Across Tables" as part of COMP6258 module
